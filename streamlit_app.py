import os
import re
import streamlit as st
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import PyPDFLoader
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.tools.retriever import create_retriever_tool
from langchain.prompts import ChatPromptTemplate
import tempfile
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain_community.utilities import SerpAPIWrapper
from langchain.agents import Tool

# .env íŒŒì¼ ë¡œë“œ
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

# âœ… í–„ì°Œ ë§íˆ¬ í›„ì²˜ë¦¬ í•¨ìˆ˜
def hamjjiify(text: str) -> str:
    """
    ìì—°ìŠ¤ëŸ½ê²Œ ë¬¸ì¥ì„ '~ì°Œ'ë¡œ ëë‚˜ê²Œ ë³€í™˜.
    - ì½”ë“œë¸”ë¡/URL/ë¦¬ìŠ¤íŠ¸/í‘œ/ì¸ë¼ì¸ì½”ë“œëŠ” ë³€í™˜ ì œì™¸
    - ë¬¸ì¥ë¶€í˜¸ê°€ ìˆìœ¼ë©´ ê·¸ ì•ì— '~ì°Œ' ì‚½ì…
    - ì´ë¯¸ '~ì°Œ'ê°€ ìˆìœ¼ë©´ ì¤‘ë³µ ì‚½ì… ë°©ì§€
    """
    if not text:
        return text

    # ``` ì½”ë“œë¸”ë¡ ë¶„ë¦¬
    parts = re.split(r"(```[\s\S]*?```)", text)

    def convert_chunk(chunk: str) -> str:
        lines = chunk.split("\n")
        out = []
        for line in lines:
            raw = line

            # ì˜ˆì™¸: ë¦¬ìŠ¤íŠ¸/ì¸ìš©/í‘œ ë¼ì¸/URL/ì¸ë¼ì¸ì½”ë“œ
            if re.match(r"^\s*([-*+]\s|>\s|\|\s*[^|]*\|)", raw) or \
               re.match(r"^\s*https?://", raw) or ("`" in raw):
                out.append(raw)
                continue

            # ë¬¸ì¥ ë‹¨ìœ„ ë¶„ë¦¬(êµ¬ë¶„ì ë’¤ ê³µë°± ê¸°ì¤€)
            sentences = re.split(r"(?<=[.!?â€¦])\s+", raw)
            converted = []
            for s in sentences:
                if not s.strip():
                    converted.append(s)
                    continue

                # ì´ë¯¸ ~ì°Œ ì¡´ì¬
                if re.search(r"~ì°Œ([.!?â€¦]|\s|$)", s):
                    converted.append(s)
                    continue

                # ë ì´ëª¨ì§€/ê³µë°± tail ë¶„ë¦¬
                m_emoji = re.search(r"([\s\U0001F300-\U0001FAFF\u2600-\u27BF]+)$", s)
                if m_emoji:
                    core = s[:m_emoji.start()]
                    tail = s[m_emoji.start():]
                else:
                    core, tail = s, ""

                # ë ë¬¸ì¥ë¶€í˜¸ ë¶„ë¦¬
                m_punct = re.search(r"([.!?â€¦]+)$", core)
                if m_punct:
                    core2 = core[:m_punct.start()]
                    punct = core[m_punct.start():]
                    converted.append(f"{core2}~ì°Œ{punct}{tail}")
                else:
                    converted.append(f"{core}~ì°Œ{tail}")

            out.append(" ".join(converted))
        return "\n".join(out)

    for i in range(len(parts)):
        if parts[i].startswith("```"):  # ì½”ë“œë¸”ë¡ì€ ê·¸ëŒ€ë¡œ
            continue
        parts[i] = convert_chunk(parts[i])

    return "".join(parts)

# âœ… SerpAPI ê²€ìƒ‰ íˆ´ ì •ì˜
def search_web():
    search = SerpAPIWrapper()

    def run_with_source(query: str) -> str:
        results = search.results(query)
        organic = results.get("organic_results", [])
        formatted = []
        for r in organic[:5]:
            title = r.get("title")
            link = r.get("link")
            source = r.get("source")
            snippet = r.get("snippet")  # âœ… snippet ì¶”ê°€
            if link:
                formatted.append(f"- [{title}]({link}) ({source})\n  {snippet}")
            else:
                formatted.append(f"- {title} (ì¶œì²˜: {source})\n  {snippet}")
        return "\n".join(formatted) if formatted else "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

    return Tool(
        name="web_search",
        func=run_with_source,
        description="ì‹¤ì‹œê°„ ë‰´ìŠ¤ ë° ì›¹ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. ê²°ê³¼ëŠ” ì œëª©+ì¶œì²˜+ë§í¬+ê°„ë‹¨ìš”ì•½(snippet) í˜•íƒœë¡œ ë°˜í™˜ë©ë‹ˆë‹¤."
    )

# âœ… PDF ì—…ë¡œë“œ â†’ ë²¡í„°DB â†’ ê²€ìƒ‰ íˆ´ ìƒì„±
def load_pdf_files(uploaded_files):
    all_documents = []
    for uploaded_file in uploaded_files:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.read())
            tmp_file_path = tmp_file.name

        loader = PyPDFLoader(tmp_file_path)
        documents = loader.load()
        all_documents.extend(documents)

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    split_docs = text_splitter.split_documents(all_documents)

    vector = FAISS.from_documents(split_docs, OpenAIEmbeddings())
    retriever = vector.as_retriever()

    retriever_tool = create_retriever_tool(
        retriever,
        name="pdf_search",
        description="Use this tool to search information from the pdf document"
    )
    return retriever_tool

# âœ… Agent ëŒ€í™” ì‹¤í–‰ (í–„ì°Œ í›„ì²˜ë¦¬ ì ìš©)
def chat_with_agent(user_input, agent_executor):
    result = agent_executor({"input": user_input})
    output = result['output']
    return hamjjiify(output)  # âœ… í–„ì°Œ ë§íˆ¬ ê°•ì œ ì ìš©

# âœ… ì„¸ì…˜ë³„ íˆìŠ¤í† ë¦¬ ê´€ë¦¬
def get_session_history(session_ids):
    if session_ids not in st.session_state.session_history:
        st.session_state.session_history[session_ids] = ChatMessageHistory()
    return st.session_state.session_history[session_ids]

# âœ… ì´ì „ ë©”ì‹œì§€ ì¶œë ¥
def print_messages():
    for msg in st.session_state["messages"]:
        st.chat_message(msg['role']).write(msg['content'])

# âœ… ë©”ì¸ ì‹¤í–‰
def main():
    st.set_page_config(page_title="AI ë¹„ì„œ", layout="wide", page_icon="ğŸ¤–")

    with st.container():
        st.image('./chatbot_logo_hamster.png', use_container_width=True)
        st.markdown('---')
        st.title("ì•ˆë…•í•˜ì„¸ìš”! RAGë¥¼ í™œìš©í•œ 'AI ë¹„ì„œ í–„í†¡ì´' ì…ë‹ˆë‹¤ ğŸ¹")

    if "messages" not in st.session_state:
        st.session_state["messages"] = []
    if "session_history" not in st.session_state:
        st.session_state["session_history"] = {}

    with st.sidebar:
        st.session_state["OPENAI_API"] = st.text_input(
            "OPENAI API í‚¤", placeholder="Enter Your API Key", type="password"
        )
        st.session_state["SERPAPI_API"] = st.text_input(
            "SERPAPI_API í‚¤", placeholder="Enter Your API Key", type="password"
        )
        st.markdown('---')
        pdf_docs = st.file_uploader(
            "Upload your PDF Files", accept_multiple_files=True, key="pdf_uploader"
        )

    # âœ… í‚¤ ì…ë ¥ í™•ì¸
    if st.session_state["OPENAI_API"] and st.session_state["SERPAPI_API"]:
        os.environ['OPENAI_API_KEY'] = st.session_state["OPENAI_API"]
        os.environ['SERPAPI_API_KEY'] = st.session_state["SERPAPI_API"]

        # ë„êµ¬ ì •ì˜
        tools = []
        if pdf_docs:
            pdf_search = load_pdf_files(pdf_docs)
            tools.append(pdf_search)
        tools.append(search_web())

        # LLM ì„¤ì •
        llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

        prompt = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    "You are a hamster character named â€˜AI Assistant Hamtokiâ€™ ğŸ¹. "
                    "You must always respond in Korean. "
                    "Speak in a friendly and kind tone, and try to naturally end every sentence with â€˜~ì°Œâ€™. "
                    "(For code, commands, URLs, or table items, you may omit â€˜~ì°Œâ€™ if necessary to stay natural.) "
                    "Always include appropriate emojis (but not too many). "
                    "When searching for information in PDFs, you must use the `pdf_search` tool first, "
                    "and if nothing is found, then use the `web_search` tool. "
                    "If the userâ€™s question contains words like â€˜latestâ€™, â€˜currentâ€™, or â€˜todayâ€™, "
                    "you must always use the `web_search` tool for real-time information. "
                    "At the beginning of the conversation, briefly introduce yourself. "
                    "Your name is â€˜AI ë¹„ì„œ í–„í†¡ì´â€™, and you end your introduction with â€˜~ì°Œ ğŸ¹âœ¨â€™."
                ),
                ("placeholder", "{chat_history}"),
                ("human", "{input} \n\n Be sure to include emoji in your responses."),
                ("placeholder", "{agent_scratchpad}"),
            ]
        )

        agent = create_tool_calling_agent(llm, tools, prompt)
        agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

        # ì…ë ¥ì°½
        user_input = st.chat_input('ì§ˆë¬¸ì´ ë¬´ì—‡ì¸ê°€ìš”?')

        if user_input:
            session_id = "default_session"
            session_history = get_session_history(session_id)

            if session_history.messages:
                prev_msgs = [{"role": msg['role'], "content": msg['content']} for msg in session_history.messages]
                response = chat_with_agent(user_input + "\n\nPrevious Messages: " + str(prev_msgs), agent_executor)
            else:
                response = chat_with_agent(user_input, agent_executor)

            st.session_state["messages"].append({"role": "user", "content": user_input})
            st.session_state["messages"].append({"role": "assistant", "content": response})

            session_history.add_message({"role": "user", "content": user_input})
            session_history.add_message({"role": "assistant", "content": response})

        print_messages()

    else:
        st.warning("OpenAI API í‚¤ì™€ SerpAPI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()
